{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avaliação Final 2021.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flekT6GFDN6m"
      },
      "source": [
        "# <span style=\"color:blue\">MBA em Ciência de Dados</span>\n",
        "# <span style=\"color:blue\">Análise de Dados com Base em Processamento Massivo em Paralelo</span>\n",
        "\n",
        "## <span style=\"color:blue\">Avaliação Final</span>\n",
        "\n",
        "**Material Produzido por:**<br>\n",
        ">**Profa. Dra. Cristina Dutra de Aguiar**<br>\n",
        "\n",
        "\n",
        "**CEMEAI - ICMC/USP São Carlos**\n",
        "\n",
        "As questões desta avaliação final estão espalhadas ao longo do texto. Por favor, procurem por Questão para encontrar a especificação das questões e o local no qual cada questão deve ser respondida. Também é possível localizar as questões utilizando o menu de navegação. O *notebook* contém a constelação de fatos da BI Solutions que deve ser utilizada para responder às questões e também todas as bibliotecas, bases de dados, inicializações, instalações, importações, geração de dataFrames, geração de visões temporárias e conversão dos tipos de dados necessárias para a realização da questão. Portanto, o notebook está preparado para ser executado usando Pandas, o método spark.sql() e os métodos do módulo pyspark.sql.\n",
        "\n",
        "O uso do *framework* Spark requer diversas configurações no ambiente de desenvolvimento para executar o *notebook*. Dado que tal complexidade foge do escopo de nossa disciplina, recomenda-se que o *notebook* seja executado na plataforma de desenvolvimento COLAB. O uso do COLAB  proporciona um ambiente de desenvolvimento pré-configurado e remove a complexidade de instalação e configuração de pacotes e *frameworks* que são utilizados na disciplina.\n",
        "\n",
        "**IMPORTANTE**\n",
        "\n",
        "**Antes de fazer a avaliação, leia atentamente a seção 5, que detalha instruções importantes sobre a avaliação e o critério de correção.**  \n",
        "\n",
        "**INSTRUÇÕES DE ENTREGA**\n",
        "\n",
        "**O que deve ser entregue:**\n",
        "- **O notebook com as respostas no formato .ipynb**\n",
        "- **O notebook com as respostas no formato .pdf**\n",
        "\n",
        "**Ambos arquivos devem ser nomeados usando o primeiro nome e o último sobrenome do aluno. Por exemplo: CristinaAguiar.ipynb e CristinaAguiar.pdf.**\n",
        "\n",
        "Boa avaliação!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o3dN_WLQcyD"
      },
      "source": [
        "#1 Constelação de Fatos da BI Solutions\n",
        "\n",
        "A aplicação de *data warehousing* da BI Solutions utiliza como base uma constelação de fatos, conforme descrita a seguir.\n",
        "\n",
        "**Tabelas de dimensão**\n",
        "\n",
        "- data (dataPK, dataCompleta, dataDia, dataMes, dataBimestre, dataTrimestre, dataSemestre, dataAno)\n",
        "- funcionario (funcPK, funcMatricula, funcNome, funcSexo, funcDataNascimento, funcDiaNascimento, funcMesNascimento, funcAnoNascimento, funcCidade, funcEstadoNome, funcEstadoSigla, funcRegiaoNome, funcRegiaoSigla, funcPaisNome, funcPaisSigla)\n",
        "- equipe (equipePK, equipeNome, filialNome, filialCidade, filialEstadoNome, filialEstadoSigla, filialRegiaoNome, filialRegiaoSigla, filialPaisNome, filialPaisSigla)\n",
        "- cargo (cargoPK, cargoNome, cargoRegimeTrabalho, cargoEscolaridadeMinima, cargoNivel)\n",
        "- cliente (clientePK, clienteNomeFantasia, clienteSetor, clienteCidade, clienteEstadoNome, clienteEstadoSigla, clienteRegiaoNome, clienteRegiaoSigla, clientePaisNome, clientePaisSigla)\n",
        "\n",
        "**Tabelas de fatos**\n",
        "- pagamento (dataPK, funcPK, equipePK, cargoPK, salario, quantidadeLancamentos)\n",
        "- negociacao (dataPK, equipePK, clientePK, receita, quantidadeNegociacoes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGeh8KdXwVCQ"
      },
      "source": [
        "#2 Obtenção dos Dados da BI Solutions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCCNC64AzBG0"
      },
      "source": [
        "## 2.1 Baixando o Módulo wget\n",
        "\n",
        "Para baixar os dados referentes ao esquema relacional da constelação de fatos da BI Solutions, é utilizado o módulo  **wget**. O comando a seguir realiza a instalação desse módulo. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e0Eao1K0EYG"
      },
      "source": [
        "#instalando o módulo wget\n",
        "%%capture\n",
        "!pip install -q wget\n",
        "!mkdir data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j56pVJ2hZ2i5"
      },
      "source": [
        "## 2.2 Obtenção dos Dados das Tabelas de Dimensão\n",
        "\n",
        "Os comandos a seguir baixam os dados que povoam as tabelas de dimensão. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46QzTpLJwfkW",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc9e6972-5b6f-44a7-f246-62ba4e9eb9c2"
      },
      "source": [
        "#baixando os dados das tabelas de dimensão\n",
        "import wget\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/data.csv\"\n",
        "wget.download(url, \"data/data.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/funcionario.csv\"\n",
        "wget.download(url, \"data/funcionario.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/equipe.csv\"\n",
        "wget.download(url, \"data/equipe.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cargo.csv\"\n",
        "wget.download(url, \"data/cargo.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cliente.csv\"\n",
        "wget.download(url, \"data/cliente.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data/cliente.csv'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o-dC7feszRc"
      },
      "source": [
        "## 2.3 Obtenção dos Dados Tabelas de Fatos\n",
        "\n",
        "Os comandos a seguir baixam os dados que povoam as tabelas de fatos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWM-CUFgBl_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "58201d6e-1a15-4afe-c91e-42ab74f6ad9a"
      },
      "source": [
        "#baixando os dados das tabelas de fatos\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/pagamento.csv\"\n",
        "wget.download(url, \"data/pagamento.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/negociacao.csv\"\n",
        "wget.download(url, \"data/negociacao.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data/negociacao.csv'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO16-7-jOioq"
      },
      "source": [
        "# 3 Apache Spark Cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVEgY9qKflBV"
      },
      "source": [
        "## 3.1 Instalação\n",
        "\n",
        "Neste *notebook* é criado um *cluster* Spark composto apenas por um **nó mestre**. Ou seja, o *cluster* não possui um ou mais **nós de trabalho** e o **gerenciador de cluster**. Nessa configuração, as tarefas (*tasks*) são realizadas no próprio *driver* localizado no **nó mestre**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaM-OnIjgLS2"
      },
      "source": [
        "Para que o cluster possa ser criado, primeiramente é instalado o Java Runtime Environment (JRE) versão 8. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXls3bfoglKW"
      },
      "source": [
        "#instalando Java Runtime Environment (JRE) versão 8\n",
        "%%capture\n",
        "!apt-get remove openjdk*\n",
        "!apt-get update --fix-missing\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BQzZfDYhb4j"
      },
      "source": [
        "Na sequência, é feito o *download* do Apache Spark versão 3.0.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a_Yv59zg3gm"
      },
      "source": [
        "#baixando Apache Spark versão 3.0.0\n",
        "%%capture\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop2.7.tgz && rm spark-3.0.0-bin-hadoop2.7.tgz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RETWX6wqhkLf"
      },
      "source": [
        "Na sequência, são configuradas as variáveis de ambiente JAVA_HOME e SPARK_HOME. Isto permite que tanto o Java quanto o Spark possam ser encontrados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZpR7NwOh2EB"
      },
      "source": [
        "import os\n",
        "#configurando a variável de ambiente JAVA_HOME\n",
        "os.environ[\"MYSQL_PWD\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#configurando a variável de ambiente SPARK_HOME\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql0z7Ro1iHQb"
      },
      "source": [
        "Por fim, são instalados dois pacotes da linguagem de programação Python, cujas funcionalidades são descritas a seguir.\n",
        "\n",
        "> **Pacote findspark:** Usado para ler a variável de ambiente SPARK_HOME e armazenar seu valor na variável dinâmica de ambiente PYTHONPATH. Como resultado, Python pode encontrar a instalação do Spark. \n",
        "\n",
        "> **Pacote pyspark:** PySpark é a API do Python para Spark. Ela possibilita o uso de Python, considerando que o *framework* Apache Spark encontra-se desenvolvido na linguagem de programação Scala. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oSYOwKljPf5"
      },
      "source": [
        "%%capture\n",
        "#instalando o pacote findspark\n",
        "!pip install -q findspark==1.4.2\n",
        "#instalando o pacote pyspark\n",
        "!pip install -q pyspark==3.0.0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAaLyjPzmIwZ"
      },
      "source": [
        "## 3.2 Conexão\n",
        "\n",
        "PySpark não é adicionado ao *sys.path* por padrão. Isso significa que não é possível importá-lo, pois o interpretador da linguagem Python não sabe onde encontrá-lo. \n",
        "\n",
        "Para resolver esse aspecto, é necessário instalar o módulo `findspark`. Esse módulo mostra onde PySpark está localizado. Os comandos a seguir têm essa finalidade.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zm1pBTEmjp4"
      },
      "source": [
        "#importando o módulo findspark\n",
        "import findspark\n",
        "#carregando a variávels SPARK_HOME na variável dinâmica PYTHONPATH\n",
        "findspark.init()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDqfefF7YUab"
      },
      "source": [
        "Depois de configurados os pacotes e módulos e inicializadas as variáveis de ambiente, é possível iniciar o uso do Spark na aplicação de `data warehousing`. Para tanto, é necessário importar o comando `SparkSession` do módulo `pyspark.sql`. São utilizados os seguintes conceitos: <br>\n",
        "\n",
        "- `SparkSession`: permite a criação de `DataFrames`. Como resultado, as tabelas relacionais podem ser manipuladas por meio de `DataFrames` e é possível realizar consultas OLAP por meio de comandos SQL. <br>\n",
        "- `builder`: cria uma instância de SparkSession. <br>\n",
        "- `appName`: define um nome para a aplicação, o qual pode ser visto na interface de usuário web do Spark. <br> \n",
        "- `master`: define onde está o nó mestre do *cluster*. Como a aplicação é executada localmente e não em um *cluster*, indica-se isso pela *string* `local` seguida do parâmetro `[*]`. Ou seja, define-se que apenas núcleos locais são utilizados. \n",
        "- `getOrCreate`: cria uma SparkSession. Caso ela já exista, retorna a instância existente. \n",
        "\n",
        "\n",
        "**Observação**: A lista completa de todos os parâmetros que podem ser utilizados na inicialização do *cluster* pode ser encontrada neste [link](https://spark.apache.org/docs/latest/spark-standalone.html#cluster-launch-scripts)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TxljJ_cwBCy"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"pyspark-notebook\").master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IpYfoG_kx_8"
      },
      "source": [
        "# 4 Geração dos DataFrames em Pandas da BI Solutions\n",
        "\n",
        "Nesta seção são gerados os DataFrames em Pandas. Atenção aos nomes desses DataFrames. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9arYf_PHlJCR"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw4NfyDZ--6z"
      },
      "source": [
        "cargoPandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cargo.csv')\n",
        "clientePandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cliente.csv')\n",
        "dataPandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/data.csv')\n",
        "equipePandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/equipe.csv')\n",
        "funcionarioPandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/funcionario.csv')\n",
        "negociacaoPandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/negociacao.csv')\n",
        "pagamentoPandas = pd.read_csv('https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/pagamento.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qL9SiR_pQE2"
      },
      "source": [
        "# 5 Geração dos DataFrames em Spark da BI Solutions\n",
        "\n",
        "Nesta seção são gerados dos DataFrames em Spark. Atenção aos nomes desses DataFrames. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRVoz-SGt87W"
      },
      "source": [
        "## 5.1 Criação dos DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "FNR-3dV6oYk4"
      },
      "source": [
        "#criando os DataFrames em Spark \n",
        "cargo = spark.read.csv(path=\"data/cargo.csv\", header=True, sep=\",\")\n",
        "cliente = spark.read.csv(path=\"data/cliente.csv\", header=True, sep=\",\")\n",
        "data = spark.read.csv(path=\"data/data.csv\", header=True, sep=\",\")\n",
        "equipe = spark.read.csv(path=\"data/equipe.csv\", header=True, sep=\",\")\n",
        "funcionario = spark.read.csv(path=\"data/funcionario.csv\", header=True, sep=\",\")\n",
        "negociacao = spark.read.csv(path=\"data/negociacao.csv\", header=True, sep=\",\")\n",
        "pagamento = spark.read.csv(path=\"data/pagamento.csv\", header=True, sep=\",\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrch9vLgjl_H"
      },
      "source": [
        "## 5.2 Atualização dos Tipos de Dados "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A_ot2pOjsWB"
      },
      "source": [
        "Nos comandos a seguir, primeiro são identificados quais colunas de quais `DataFrames` devem ser do tipo de dado inteiro. Na sequência, ocorre a conversão. Por fim, são exibidos os esquemas dos `DataFrames`, possibilitando visualizar a mudança de tipo de dados das colunas especificadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmCV6Mur__z6"
      },
      "source": [
        "# identificando quais colunas de quais DataFrames devem ser do tipo de dado inteiro\n",
        "colunas_cargo = [\"cargoPK\"]\n",
        "colunas_cliente = [\"clientePK\"]\n",
        "colunas_data = [\"dataPK\", \"dataDia\", \"dataMes\", \"dataBimestre\", \"dataTrimestre\", \"dataSemestre\", \"dataAno\"]\n",
        "colunas_equipe = [\"equipePK\"]\n",
        "colunas_funcionario = [\"funcPK\", \"funcDiaNascimento\", \"funcMesNascimento\", \"funcAnoNascimento\"]\n",
        "colunas_negociacao = [\"equipePK\", \"clientePK\", \"dataPK\", \"quantidadeNegociacoes\"]\n",
        "colunas_pagamento = [\"funcPK\", \"equipePK\", \"dataPK\", \"cargoPK\", \"quantidadeLancamentos\"]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPNnDJcG9R5H"
      },
      "source": [
        "# importando o tipo de dado desejado\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "\n",
        "# atualizando o tipo de dado das colunas especificadas \n",
        "# substituindo as colunas já existentes \n",
        "\n",
        "for coluna in colunas_cargo:\n",
        "  cargo = cargo.withColumn(coluna, cargo[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_cliente:\n",
        "  cliente = cliente.withColumn(coluna, cliente[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_data:\n",
        "  data = data.withColumn(coluna, data[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_equipe:\n",
        "  equipe = equipe.withColumn(coluna, equipe[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_funcionario:\n",
        "  funcionario = funcionario.withColumn(coluna, funcionario[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_negociacao:\n",
        "  negociacao = negociacao.withColumn(coluna, negociacao[coluna].cast(IntegerType()))\n",
        "\n",
        "for coluna in colunas_pagamento:\n",
        "  pagamento = pagamento.withColumn(coluna, pagamento[coluna].cast(IntegerType()))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0dX_7U_AzIY"
      },
      "source": [
        "Nos comandos a seguir, primeiro são identificados quais colunas de quais `DataFrames` devem ser do tipo de dado número de ponto flutuante. Na sequência, ocorre a conversão. Por fim, são exibidos os esquemas dos `DataFrames`, possibilitando visualizar a mudança de tipo de dados das colunas especificadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBcQ7Ep7AWqN"
      },
      "source": [
        "# identificando quais colunas de quais DataFrames devem ser do tipo de dado número de ponto flutuante\n",
        "colunas_negociacao = [\"receita\"]\n",
        "colunas_pagamento = [\"salario\"]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcfvkIK1BRSp"
      },
      "source": [
        "# importando o tipo de dado desejado\n",
        "from pyspark.sql.types import FloatType\n",
        "\n",
        "\n",
        "# atualizando o tipo de dado das colunas especificadas \n",
        "# substituindo as colunas já existentes \n",
        "\n",
        "for coluna in colunas_negociacao:\n",
        "  negociacao = negociacao.withColumn(coluna, negociacao[coluna].cast(FloatType()))\n",
        "\n",
        "for coluna in colunas_pagamento:\n",
        "  pagamento = pagamento.withColumn(coluna, pagamento[coluna].cast(FloatType()))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91nwfsV3_rKs"
      },
      "source": [
        "# importando funções adicionais \n",
        "from pyspark.sql.functions import round, desc"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wN5iOGKwnHG"
      },
      "source": [
        "## 5.3 Criação de Visões Temporárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJsqRI3TwsjS"
      },
      "source": [
        "#criando as visões temporárias \n",
        "cargo.createOrReplaceTempView(\"cargo\")\n",
        "cliente.createOrReplaceTempView(\"cliente\")\n",
        "data.createOrReplaceTempView(\"data\")\n",
        "equipe.createOrReplaceTempView(\"equipe\")\n",
        "funcionario.createOrReplaceTempView(\"funcionario\")\n",
        "negociacao.createOrReplaceTempView(\"negociacao\")\n",
        "pagamento.createOrReplaceTempView(\"pagamento\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkL4w2MMudL7"
      },
      "source": [
        "# 6 Instruções Importantes sobre a Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKdDsHnDwlaH"
      },
      "source": [
        "## 6.1 Especificação das Consultas OLAP\n",
        "\n",
        "As consultas OLAP devem ser respondidas de acordo com o solicitado em cada questão. As seguintes solicitações podem ser feitas:\n",
        "\n",
        "- Resolva a questão especificando a consulta OLAP usando **Pandas**. Neste caso, a consulta deve ser respondida usando os conceitos apresentados na Aula 05 da disciplina. Ou seja, a consulta deve ser respondida usando os métodos disponíveis na biblioteca Pandas para uso em Python. Não é possível usar o método `spark.sql()` para especificar a consulta. Também não é possível usar os demais métodos do módulo `pyspark.sql` para especificar a consulta.\n",
        "\n",
        "- Resolva a questão especificando a consulta OLAP na **linguagem SQL**. Neste caso, a consulta deve ser respondida usando os conceitos apresentados na Aula 07 da disciplina. Ou seja, a consulta deve ser respondida usando a linguagem SQL textual e o método `spark.sql()`. Não é possível usar os métodos disponíveis na biblioteca Pandas para especificar a consulta. Também não é possível usar os demais métodos do módulo `pyspark.sql` para especificar a consulta, com exceção do método `show()` para listar o resultado da consulta. \n",
        "\n",
        "- Resolva a questão especificando a consulta OLAP usando os **métodos de pyspark.sql**. Neste caso, a consulta deve ser respondida usando os conceitos apresentados na Aula 08 da disciplina. Ou seja, a consulta deve ser respondida usando os demais métodos do módulo `pyspark.sql`. Não é possível usar os métodos disponíveis na biblioteca Pandas para especificar a consulta. Também não é possível usar o método `spark.sql()` para especificar a consulta.\n",
        "\n",
        "**AVISO: Caso a consulta seja especificada de forma diferente do que foi solicitado, a resposta não será considerada, mesmo que ela esteja correta.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsrYR2SJw-x3"
      },
      "source": [
        "## 6.2 Ordem das Colunas e das Linhas\n",
        "\n",
        "A resolução das questões deve seguir estritamente as especificações definidas em cada consulta. Isto significa que:\n",
        "\n",
        "- As **colunas** solicitadas devem ser exibidas exatamente na mesma ordem que a definida na questão. Note que todas as colunas a serem exibidas como resposta da consulta, bem como a ordem na qual elas devem aparecer são sempre definidas na questão. \n",
        "\n",
        "- As **linhas** retornadas como respostas devem ser exibidas exatamente na mesma ordem que a definida na questão. Note que a ordem na qual as linhas devem aparecer são sempre definidas na questão. \n",
        "\n",
        "- Os **nomes das colunas** renomeadas devem seguir estritamente os nomes definidos na questão. Para evitar possíveis erros, os nomes das colunas renomeadas não possuem acentos e espaços em branco, além de serem escritos utilizando apenas letras maiúsculas. Note que os nomes das colunas renomeadas são sempre definidos na questão.\n",
        "\n",
        "**AVISO: Essas orientações devem ser seguidas uma vez que a correção da avaliação será realizada de forma automática. Caso a consulta retorne resultados de forma diferente do que foi solicitado, a resposta não será considerada, mesmo que ela esteja correta.**  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AZ0475X4L59"
      },
      "source": [
        "## 6.3 Listagem das Respostas das Consultas\n",
        "\n",
        "A resposta de cada consulta deve ser listada usando o método `show()`. Nenhum outro método pode ser utilizado com essa finalidade.  \n",
        "\n",
        "Devem ser listadas apenas as `25` primeiras linhas de resposta de cada consulta. Adicionalmente, devem ser listadas *strings* com tamanho maior do que 20 caracteres, ou seja, o parâmetro `truncate` do método `show()` deve ser inicializado como `false`.\n",
        "\n",
        "Portanto, a listagem das respostas deve ser feita utilizando o método `show()` como especificado a seguir. \n",
        "\n",
        "- Quando a consulta OLAP for especificada usando **Pandas**. Utilize o comando `df.head(25)` para exibir o resultado da consulta.\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando a **linguagem SQL**. Utilize o comando `spark.sql(consultaSQL).show(25,truncate=False)` para exibir o resultado da consulta. \n",
        "\n",
        "- Quando a consulta OLAP for especificada usando os demais **métodos de pyspark.sql**. Utilize o comando `nomeDoDataFrame.show(25,truncate=False)` para exibir o resultado da consulta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzIcWYeOVOsN"
      },
      "source": [
        "## 6.4 Arredondamento dos Dados\n",
        "\n",
        "Deve ser realizado o arredondamento dos dados todas as vezes que uma função de agregação for aplicada às medidas numéricas `salario` da tabela de dimensão `pagamento` e `receita` da tabela de dimensão `negociacao`. \n",
        "\n",
        "O arredondamento deve ser realizado usando a função `round()` na linguagem SQL e o método `round()` em `pyspark.sql` e deve arredondar os dados até duas casas decimais. Por exemplo, podem ser produzidos resultados da forma `112233.4` e `112233.44`. \n",
        "\n",
        "Portanto, o arredondamento dos dados deve ser feito como especificado a seguir.\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando **Pandas**. Utilize o comando `df.round(2)` para arredondar os dados até duas casas decimais.\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando a **linguagem SQL**. Utilize a função `ROUND(funçãoDeAgregação,2)` para arredondar o dado até duas casas decimais.\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando os demais **métodos de pyspark.sql**. Utilize o método `round(funçãoDeAgregação,2)` para arredondar o dado até duas casas decimais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LOtvy-LrJ32"
      },
      "source": [
        "## 6.5 Respostas das Questões\n",
        "\n",
        "As respostas das questões devem ser fornecidas de duas formas diferentes:\n",
        "\n",
        "- Exibidas na saída padrão.\n",
        "\n",
        "- Armazenadas em um arquivo no formato csv.\n",
        "\n",
        "A seguir são detalhadas as instruções em **Pandas**, **spark.sql()** e **pyspark()** para que as respostas sejam mostradas de forma apropriada para as correções. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drW2AS_V1MMr"
      },
      "source": [
        "Em **Pandas**\n",
        "\n",
        "```python\n",
        "# Resolve a questão usando a variável de nome questao\n",
        "QuestaoX = consulta.round(2).head(25)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "display(QuestaoX)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "QuestaoX.to_csv(\"questaoX.csv\", index=False, header=True)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaYNdTpk2PbL"
      },
      "source": [
        "**Em spark.sql()**\n",
        "\n",
        "```python\n",
        "# Resolve a questão usando a variável de nome questao\n",
        "QuestaoX = spark.sql(query)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ... \n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "QuestaoX.show(25, truncate=False)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "QuestaoX\\\n",
        "  .coalesce(1).limit(25) \\\n",
        "  .toPandas().to_csv(\"questaoX.csv\", index=False, header=True)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG8Y5lT72eCS"
      },
      "source": [
        "**Em pyspark()**\n",
        "\n",
        "```python\n",
        "# Resolve a questão usando a variável de nome questao\n",
        "QuestaoX = consulta \n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "QuestaoX.show(25, truncate=False)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "QuestaoX\\\n",
        "  .coalesce(1).limit(25) \\\n",
        "  .toPandas().to_csv(\"QuestaoX.csv\", index=False, header=True)\n",
        "onde X é o número da questão, por exemplo Questao1, Questao2, ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQVQqm0pNDS1"
      },
      "source": [
        "## 6.6 Comentários Explicativos\n",
        "\n",
        "Devem ser colocados comentários no código que expliquem o passo a passo da resolução da questão. Os comentários explicativos devem ser realizados como especificado a seguir. \n",
        "\n",
        "- Quando a consulta OLAP for especificada usando **Pandas**. Utilize `#` para colocar comentário. Por exemplo:\n",
        "\n",
        "```\n",
        "# para a solução desta consulta OLAP, primeiramente é aplicado o método ... para ..... \n",
        "# Na sequência, é aplicado o método ... para ...\n",
        "```\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando a **linguagem SQL**. Utilize `#` para colocar comentários gerais (conforme explicado para os demais métodos de `pyspark.sql`) ou utilize `--` para colocar comentários no comando SQL. Por exemplo:\n",
        "\n",
        "```\n",
        "# neste comentário são descritas as características de cada cláusula da consulta SQL. \n",
        "# A funcionalidade da cláusula SELECT nesta consulta é ... \n",
        "# A funcionalidade da cláusula FROM nesta consulta é ... \n",
        "# A funcionalidade da cláusula WHERE nesta consulta é ...\n",
        "```\n",
        "\n",
        "```\n",
        "-- A funcionalidade da cláusula SELECT nesta consulta é ...\n",
        "SELECT funcNome\n",
        "-- A funcionalidade da cláusula FROM nesta consulta é ...\n",
        "FROM funcionario\n",
        "-- A funcionalidade da cláusula WHERE nesta consulta é ...\n",
        "WHERE funcPK = 1\n",
        "```\n",
        "\n",
        "- Quando a consulta OLAP for especificada usando os demais **métodos de pyspark.sql**. Utilize `#` para colocar comentário. Por exemplo:\n",
        "\n",
        "```\n",
        "# para a solução desta consulta OLAP, primeiramente é aplicado o método ... para ..... \n",
        "# Na sequência, é aplicado o método ... para ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IcbpvZHPn3S"
      },
      "source": [
        "## 6.7 Indentação e Organização\n",
        "\n",
        "As consultas e os comandos que respondem às questões dessa avaliação devem ser escritos de forma indentada. Em caso de dúvida, observem os *notebooks* da Aula 05, da Aula 07 e da Aula 08 e verifiquem como as consultas e os comandos foram indentados.\n",
        "\n",
        "**AVISO: Com relação à organização, é necessário que as respostas às questões sejam localizadas aonde especificado no *notebook*. Por favor, procurem por \"Resposta da Questão\" para encontrar o local no qual as respostas devem ser especificadas. Também é possível localizar o local das respostas utilizando o menu de navegação.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFjCivy1Mg-A"
      },
      "source": [
        "## 6.8 Critério de Avaliação\n",
        "\n",
        "Na correção da avaliação, serão ponderados os seguintes aspectos:\n",
        "\n",
        "- Corretude da execução das consultas OLAP.\n",
        "\n",
        "- Atendimento às especificações definidas nas seções 6.1, 6.2, 6.3, 6.4, 6.5.\n",
        "\n",
        "- Atendimento às especificações da sintaxe das cláusulas e dos métodos utilizados para resolver cada questão.\n",
        "\n",
        "- Qualidade da documentação entregue, de acordo com as especificações definidas nas seções 6.6 e 6.7. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss0pmgplPAL3"
      },
      "source": [
        "# 7 Consultas OLAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_emI31_-uYc5"
      },
      "source": [
        "O objetivo das consultas OLAP é realizar diferentes investigações sobre aspectos específicos no que tange às atividades realizadas pela BI Solutions. Os resultados obtidos nas investigações poderão ser posteriormente utilizados para a definição de estratégias que a empresa deve executar para prover melhorias. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CrGAAl0s6f4"
      },
      "source": [
        "## 7.1 Análises Relacionadas aos Cargos\n",
        "\n",
        "Foi identificado que, nos últimos anos, o cargo de nome \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\" teve um aumento expressivo no que tange aos gastos com salários. O objetivo das análises desta seção é obter uma visão relacionada a esse aspecto, por meio da investigação dos gastos em salários considerando diferentes fatores. \n",
        "\n",
        "Podem ser realizadas diferentes análises, sendo que três delas são solicitadas a seguir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zi-gqUljW18"
      },
      "source": [
        "### **Questão 1 (valor 1,0)**\n",
        "\n",
        "Liste, para cada ano, a soma dos salários para o cargo de nome \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\". Arredonde a soma dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ANO\", \"TOTALDESPESA\". Ordene as linhas exibidas primeiro pelo total de despesa em ordem descendente e depois pelo ano em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*. \n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP usando Pandas**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcSouuCk6N0-"
      },
      "source": [
        "### Resposta da Questão 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kKTtt-V6TKI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7268a09b-d644-40ea-9d58-79b6847cac3f"
      },
      "source": [
        "# Resposta da Questão 1 \n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .head()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão\n",
        "\n",
        "# Realizar join de datas e cargos\n",
        "# Filtrar pelo cargo de nome \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\" \n",
        "consulta = pagamentoPandas.merge(dataPandas, on = 'dataPK')\\\n",
        ".merge(cargoPandas, on = 'cargoPK').query('cargoNome == \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\"')\n",
        "\n",
        "# Renomear colunas para o padrão definido e realizar a soma dos salarios agrupando por ano\n",
        "consulta = consulta.rename(mapper={\"dataAno\": \"ANO\", \"salario\": \"TOTALDESPESA\"}, axis=1)\n",
        "\n",
        "# Agrupando por ANO e TOTALDESPESA e somando o resultado\n",
        "consulta = consulta.groupby(['ANO'])['TOTALDESPESA'].sum().reset_index()\n",
        "\n",
        "# Aplicando ordenação descendente para as colunas 'ANO', 'TOTALDESPESA'\n",
        "consulta = consulta.sort_values(by = ['ANO', 'TOTALDESPESA'], ascending=[False,False])\n",
        "\n",
        "Questao1 = consulta.round(2).head(25)\n",
        "\n",
        "# Exibe a resposta na saída padrão\n",
        "display(Questao1)\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta\n",
        "Questao1.to_csv(\"questao1.csv\", index=False, header=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ANO</th>\n",
              "      <th>TOTALDESPESA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020</td>\n",
              "      <td>1883273.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019</td>\n",
              "      <td>1883273.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018</td>\n",
              "      <td>1239394.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017</td>\n",
              "      <td>943759.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016</td>\n",
              "      <td>475625.52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ANO  TOTALDESPESA\n",
              "4  2020    1883273.28\n",
              "3  2019    1883273.28\n",
              "2  2018    1239394.80\n",
              "1  2017     943759.32\n",
              "0  2016     475625.52"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FANzdCl6mAS"
      },
      "source": [
        "### **Questão 2 (valor: 1,0)**\n",
        "\n",
        "Liste, para cada nome da região da filial, a soma dos salários para o cargo de nome \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\". Arredonde a soma dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"REGIAO\", \"TOTALDESPESA\". Ordene as linhas exibidas primeiro pelo total de despesa em ordem descendente e depois pelo nome da região em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*. \n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP na linguagem SQL**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpFnRTk369Q5"
      },
      "source": [
        "### Resposta da Questão 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVQ-d4CJ7AEt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "143a7dce-8c48-4bcd-d34b-2a250e7a1658"
      },
      "source": [
        "# Resposta da Questão 2\n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .show()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão\n",
        "\n",
        "\n",
        "query = \"\"\"\n",
        "-- Seleção de regiao e soma dos salarios com rename de coluna para padrão desejado\n",
        "SELECT filialRegiaoNome as REGIAO, ROUND(SUM(salario),2) AS TOTALDESPESA\n",
        "FROM pagamento \n",
        "-- Join com as duas tabelas alvos (data para agrupamento e equipe para filtro)\n",
        "JOIN data USING (dataPK)\n",
        "JOIN cargo USING (cargoPK)\n",
        "JOIN equipe USING (equipePK)\n",
        "WHERE \n",
        "-- Filtro por cargo\n",
        "cargo.cargoNome == \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\"\n",
        "-- Agrupamento por REGIAO\n",
        "GROUP BY REGIAO\n",
        "-- Ordenação descendente por ano e totaldespesa \n",
        "ORDER BY REGIAO DESC, TOTALDESPESA DESC\n",
        "\"\"\"\n",
        "\n",
        "# Enviando a query SQL para execução\n",
        "Questao2  = spark.sql(query)\n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "Questao2.show(25, truncate=False)\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "Questao2\\\n",
        "  .coalesce(1).limit(25) \\\n",
        "  .toPandas().to_csv(\"questao2.csv\", index=False, header=True)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+\n",
            "|REGIAO      |TOTALDESPESA|\n",
            "+------------+------------+\n",
            "|SUDESTE     |3923904.22  |\n",
            "|NORDESTE    |932295.13   |\n",
            "|CENTRO-OESTE|1569126.83  |\n",
            "+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj03JRHf7-am"
      },
      "source": [
        "### **Questão 3 (valor: 1,0)**\n",
        "\n",
        "Liste, por sexo, a soma dos salários para o cargo de nome \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\". Arredonde a soma dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"SEXO\", \"TOTALDESPESA\". Ordene as linhas exibidas primeiro pelo total de despesa em ordem descendente e depois pelo sexo em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*. \n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP usando os métodos de pyspark.sql**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCpy46lL8Xdn"
      },
      "source": [
        "### Resposta da Questão 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq3uXrzT8jO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ed0931f6-f31a-4de8-c129-171b9b17d161"
      },
      "source": [
        "# Resposta da Questão 3\n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .show()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão\n",
        "\n",
        "# Realizar join de datas e cargos\n",
        "# Filtrar pelo cargo de nome \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\" \n",
        "\n",
        "# Join da tabela pagamento com data usando a PK dataPK\n",
        "query = pagamento.join(data, 'dataPK', 'inner')\n",
        "# Join da tabela funcionario com pagamento usando a PK funcPK\n",
        "query = query.join(funcionario, 'funcPK', 'inner')\n",
        "# Join com a tabela cargo com pagamento usando PK cargoPK e filtro de cargo por nome\n",
        "query = query.join(cargo, (cargo.cargoPK ==  pagamento.cargoPK) & (cargo.cargoNome == \"ADMINISTRADOR EM SEGURANCA DA INFORMACAO\"),'inner')\n",
        "\n",
        "#Selecionando campos alvos da consulta\n",
        "query = query.select('funcSexo','salario','cargoNome')\n",
        "\n",
        "#Agrupamento por sexo\n",
        "query = query.groupBy('funcSexo')\n",
        "\n",
        "#Soma dos salários\n",
        "query = query.sum(\"salario\")\\\n",
        "\n",
        "#Arredondamento da soma de salário para duas casa decimais\n",
        "query = query.withColumn(\"sum(salario)\", round(\"sum(salario)\",2))\n",
        "\n",
        "#Rename de colunas\n",
        "query = query.withColumnRenamed(\"sum(salario)\", \"TOTALDESPESA\")\n",
        "query = query.withColumnRenamed(\"funcSexo\", \"SEXO\")\n",
        "\n",
        "##Ordenação por TOTALDESPESA e SEXO em ordem descrescente\n",
        "Questao3 = query.orderBy(desc(\"TOTALDESPESA\"), desc('SEXO'))\n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "Questao3.show(25, truncate=False)\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "Questao3\\\n",
        "  .coalesce(1).limit(25) \\\n",
        "  .toPandas().to_csv(\"Questao3.csv\", index=False, header=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------+\n",
            "|SEXO|TOTALDESPESA|\n",
            "+----+------------+\n",
            "|M   |4380094.08  |\n",
            "|F   |2045232.1   |\n",
            "+----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6s9Og_xCPc4"
      },
      "source": [
        "## 7.2 Análises Relacionadas às Regiões\n",
        "\n",
        "Foi identificada a necessidade de se investigar despesas e receitas no que tange às regiões. O objetivo das análises desta seção é obter uma visão relacionada a esse aspecto. \n",
        "\n",
        "Podem ser realizadas diferentes análises, sendo que três delas são solicitadas a seguir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wy13GBocw36"
      },
      "source": [
        "### **Questão 4 (valor: 1,0)** \n",
        "\n",
        "Liste, para cada nome do estado da filial, a soma das receitas por ano considerando apenas o trimestre 1 e os clientes cuja região na qual eles moram é a mesma região na qual a filial está localizada. Arredonde a soma das receitas para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ESTADO\", \"ANO\", \"TOTALRECEITA\". Ordene as linhas exibidas primeiro pelo total de receitas em ordem descendente, depois por estado em ordem descendente, depois pelo ano em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*.\n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP usando Pandas**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzhYPIvqnLc8"
      },
      "source": [
        "### Resposta da Questão 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd8CD2zLmnLe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "b8dbe603-a297-41a6-eeb6-8d2e8dfec3a0"
      },
      "source": [
        "# Resposta da Questão 4 \n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .head()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão\n",
        "\n",
        "\n",
        "# Realizando merge da tabela de negociação com a tabela de clientes através da chave primária clientePK\n",
        "consulta  = negociacaoPandas.merge(clientePandas, on = 'clientePK')\\\n",
        "\n",
        "# Realizando merge com a tabela data através da chave primária dataPK (negociacao.dataPK == data.dataPK)\n",
        "consulta = consulta.merge(dataPandas, on = 'dataPK')\n",
        "\n",
        "# Filtrar somente os registros cujo a data.dataTrimestre == 1\n",
        "consulta = consulta.query('dataTrimestre == 1')\n",
        "\n",
        "# Renomear colunas para o padrão definido \n",
        "consulta = consulta.rename(mapper={\"dataAno\": \"ANO\", \"clienteEstadoNome\": \"ESTADO\", 'receita':'TOTALRECEITA'}, axis=1)\n",
        "\n",
        "# Agrupando por ANO e ESTADO somando o TOTALRECEITA\n",
        "consulta = consulta.groupby(['ANO','ESTADO'])['TOTALRECEITA'].sum().reset_index()\n",
        "\n",
        "# Aplicando ordenação descendente para as colunas 'TOTALRECEITA','ESTADO','ANO' em roder descendente\n",
        "consulta = consulta.sort_values(by = ['TOTALRECEITA','ESTADO','ANO'], ascending=[False,False,False])\n",
        "\n",
        "Questao4 = consulta.round(2).head(25)\n",
        "\n",
        "# Exibe a resposta na saída padrão\n",
        "display(Questao4)\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta\n",
        "Questao4.to_csv(\"questao4.csv\", index=False, header=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ANO</th>\n",
              "      <th>ESTADO</th>\n",
              "      <th>TOTALRECEITA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2019</td>\n",
              "      <td>SAO PAULO</td>\n",
              "      <td>3901649.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2020</td>\n",
              "      <td>SAO PAULO</td>\n",
              "      <td>2848293.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2019</td>\n",
              "      <td>RIO DE JANEIRO</td>\n",
              "      <td>1706011.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>2020</td>\n",
              "      <td>RIO DE JANEIRO</td>\n",
              "      <td>1482059.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2018</td>\n",
              "      <td>SAO PAULO</td>\n",
              "      <td>1073581.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2019</td>\n",
              "      <td>MINAS GERAIS</td>\n",
              "      <td>827838.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>2020</td>\n",
              "      <td>MINAS GERAIS</td>\n",
              "      <td>776380.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2019</td>\n",
              "      <td>CEARA</td>\n",
              "      <td>598676.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2019</td>\n",
              "      <td>PERNAMBUCO</td>\n",
              "      <td>539018.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2020</td>\n",
              "      <td>PARANA</td>\n",
              "      <td>528529.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2018</td>\n",
              "      <td>MINAS GERAIS</td>\n",
              "      <td>513619.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2019</td>\n",
              "      <td>RIO GRANDE DO SUL</td>\n",
              "      <td>501445.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2020</td>\n",
              "      <td>AMAZONAS</td>\n",
              "      <td>464345.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2017</td>\n",
              "      <td>SAO PAULO</td>\n",
              "      <td>460565.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2019</td>\n",
              "      <td>AMAZONAS</td>\n",
              "      <td>414695.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>2020</td>\n",
              "      <td>MATO GROSSO DO SUL</td>\n",
              "      <td>410833.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>2020</td>\n",
              "      <td>RIO GRANDE DO SUL</td>\n",
              "      <td>409673.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>2020</td>\n",
              "      <td>CEARA</td>\n",
              "      <td>406246.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2018</td>\n",
              "      <td>RIO DE JANEIRO</td>\n",
              "      <td>355304.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2016</td>\n",
              "      <td>SAO PAULO</td>\n",
              "      <td>330858.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2019</td>\n",
              "      <td>PARANA</td>\n",
              "      <td>300838.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2018</td>\n",
              "      <td>CEARA</td>\n",
              "      <td>263980.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2020</td>\n",
              "      <td>PERNAMBUCO</td>\n",
              "      <td>239792.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2018</td>\n",
              "      <td>PERNAMBUCO</td>\n",
              "      <td>238991.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>2020</td>\n",
              "      <td>SANTA CATARINA</td>\n",
              "      <td>227591.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ANO              ESTADO  TOTALRECEITA\n",
              "39  2019           SAO PAULO    3901649.25\n",
              "49  2020           SAO PAULO    2848293.65\n",
              "36  2019      RIO DE JANEIRO    1706011.15\n",
              "46  2020      RIO DE JANEIRO    1482059.40\n",
              "29  2018           SAO PAULO    1073581.65\n",
              "33  2019        MINAS GERAIS     827838.95\n",
              "43  2020        MINAS GERAIS     776380.25\n",
              "31  2019               CEARA     598676.30\n",
              "35  2019          PERNAMBUCO     539018.50\n",
              "44  2020              PARANA     528529.60\n",
              "23  2018        MINAS GERAIS     513619.05\n",
              "37  2019   RIO GRANDE DO SUL     501445.05\n",
              "40  2020            AMAZONAS     464345.10\n",
              "19  2017           SAO PAULO     460565.75\n",
              "30  2019            AMAZONAS     414695.20\n",
              "42  2020  MATO GROSSO DO SUL     410833.15\n",
              "47  2020   RIO GRANDE DO SUL     409673.55\n",
              "41  2020               CEARA     406246.35\n",
              "26  2018      RIO DE JANEIRO     355304.95\n",
              "9   2016           SAO PAULO     330858.55\n",
              "34  2019              PARANA     300838.10\n",
              "21  2018               CEARA     263980.70\n",
              "45  2020          PERNAMBUCO     239792.40\n",
              "25  2018          PERNAMBUCO     238991.00\n",
              "48  2020      SANTA CATARINA     227591.25"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYHOKEoMaMg_"
      },
      "source": [
        "### **Questão 5 (valor: 1,0)** \n",
        "\n",
        "Liste, para cada nome da região da filial, a soma dos salários e a soma das receitas, considerando apenas o ano de 2017. Arredonde a soma dos salários e a soma das receitas para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"REGIAO\", \"TOTALRECEITAEQUIPE\", \"TOTALDESPESAEQUIPE\". Ordene as linhas exibidas primeiro pelo total de receitas em ordem descendente, depois pelo total de despesas ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*. \n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP na linguagem SQL**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Og3mkliav8c"
      },
      "source": [
        "### Resposta da Questão 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju_T2ILOa0Km",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4be80c61-3484-4c5b-f1c4-40f0c1a808b2"
      },
      "source": [
        "# Resposta da Questão 5\n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .show()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT \n",
        "\n",
        "-- selecionar a região da filial\n",
        "filialRegiaoNome as REGIAO, \n",
        "\n",
        "-- Soma das despesas com arredondamento em duas casas\n",
        "ROUND(SUM(salario),2) AS TOTALDESPESAEQUIPE,\n",
        "\n",
        "-- Soma das receitas com arredondamento em duas casas\n",
        "ROUND(SUM(receita),2) AS TOTALRECEITAEQUIPE\n",
        "\n",
        "-- Seleção das tabelas equipe (usado no campo filialRegiaoNome) e data (para filtro match com pagamento e negociação)\n",
        "FROM equipe, data\n",
        "\n",
        "-- join  de pagamentos da mesma equipe e data\n",
        "INNER JOIN pagamento ON pagamento.equipePK = equipe.equipePK AND pagamento.dataPK = data.dataPK\n",
        "\n",
        "-- join  de necocição da mesma equipe e data\n",
        "INNER JOIN negociacao ON negociacao.equipePK = equipe.equipePK AND negociacao.dataPK = data.dataPK\n",
        "\n",
        "-- Filtrando apenas pelo ano de 2017\n",
        "WHERE  data.dataAno == 2017\n",
        "\n",
        "-- Agrupamento por REGIAO\n",
        "GROUP BY REGIAO\n",
        "-- Ordenação descendente por TOTALDESPESAEQUIPE e TOTALRECEITAEQUIPE \n",
        "ORDER BY TOTALDESPESAEQUIPE DESC, TOTALRECEITAEQUIPE DESC\n",
        "\"\"\"\n",
        "\n",
        "# Enviando a query SQL para execução\n",
        "Questao5  = spark.sql(query)\n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "Questao5.show(25, truncate=False)\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "Questao5\\\n",
        "  .coalesce(1).limit(25) \\\n",
        "  .toPandas().to_csv(\"questao5.csv\", index=False, header=True)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------------+------------------+\n",
            "|REGIAO      |TOTALDESPESAEQUIPE|TOTALRECEITAEQUIPE|\n",
            "+------------+------------------+------------------+\n",
            "|SUDESTE     |2359394.58        |6703714.63        |\n",
            "|CENTRO-OESTE|606071.4          |754395.4          |\n",
            "+------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzcUw0CYHPB1"
      },
      "source": [
        "### **Questão 6 (valor: 1,5)** \n",
        "\n",
        "Liste todas as agregações que podem ser geradas para a partir da soma dos salários por nome do estado da filial e por ano, considerando apenas o trimestre 1 e os funcionários cuja região na qual eles moram é a mesma região na qual a filial está localizada. Arredonde a soma dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ESTADO\", \"ANO\", \"TOTALRECEITA\". Ordene as linhas exibidas primeiro pelo total de receita em ordem descendente, depois por estado em ordem descendente, depois pelo ano em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*. \n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP usando os métodos de pyspark.sql.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqBE_EVMnO0S"
      },
      "source": [
        "### Resposta da Questão 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiPX1LsrmqJS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bedd4505-57d5-4a8e-fe84-e0e330a502a7"
      },
      "source": [
        "# Resposta da Questão 6\n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .show()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão\n",
        "\n",
        "\n",
        "#Selecionar tabela de fatos pagamento\n",
        "query = pagamento\n",
        "# Join com data através da PK dataPK e filtro por semestre 1\n",
        "query = query.join(data, (pagamento.dataPK == data.dataPK) & (data.dataTrimestre==1), 'inner')\n",
        "# Join com tabela de equipe através da PK equipePK para acesso ao campo filialEstadoNome e filtro pela filialRegiaoNome\n",
        "query = query.join(equipe, 'equipePK', 'inner')\n",
        "# Join com a tabela de funcionário usando como junção o pagamento e cuja a região na qual o funcionario reside é a mesma região na qual a filial está localizada\n",
        "query = query.join(funcionario, (funcionario.funcPK == pagamento.funcPK ) & (funcionario.funcRegiaoNome == equipe.filialRegiaoNome), 'inner')\n",
        "\n",
        "# Selecão dos campos para uso\n",
        "query = query.select('dataAno','filialEstadoNome','salario')\n",
        "\n",
        "#Dimensões das agregações para todas as combinações de valores nas colunas selecionadas\n",
        "query = query.cube('dataAno','filialEstadoNome')\n",
        "#soma de salário para cada conjunto de agregação\n",
        "query = query.sum(\"salario\")\n",
        "# Arrendondamento para duas casas decimais\n",
        "query = query.withColumn(\"sum(salario)\", round(\"sum(salario)\",2))\n",
        "#Rename de colunas\n",
        "query = query.withColumnRenamed(\"sum(salario)\", \"TOTALRECEITA\")\n",
        "query = query.withColumnRenamed(\"dataAno\", \"ANO\")\n",
        "query = query.withColumnRenamed(\"filialEstadoNome\", \"ESTADO\")\n",
        "\n",
        "#Ordenação\n",
        "Questao6 = query.orderBy(desc(\"TOTALRECEITA\"), desc('ANO'))\n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "Questao6.show(25, truncate=False)\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "Questao6\\\n",
        "  .coalesce(1).limit(25) \\\n",
        "  .toPandas().to_csv(\"Questao6.csv\", index=False, header=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------+------------+\n",
            "|ANO |ESTADO        |TOTALRECEITA|\n",
            "+----+--------------+------------+\n",
            "|null|null          |9342133.85  |\n",
            "|null|SAO PAULO     |5657776.45  |\n",
            "|null|RIO DE JANEIRO|3549567.87  |\n",
            "|2020|null          |2450982.1   |\n",
            "|2019|null          |2450982.1   |\n",
            "|2018|null          |2065272.34  |\n",
            "|2017|null          |1550525.2   |\n",
            "|2020|SAO PAULO     |1514279.37  |\n",
            "|2019|SAO PAULO     |1514279.37  |\n",
            "|2018|SAO PAULO     |1195964.37  |\n",
            "|2017|SAO PAULO     |957678.16   |\n",
            "|2020|RIO DE JANEIRO|869307.97   |\n",
            "|2019|RIO DE JANEIRO|869307.97   |\n",
            "|2018|RIO DE JANEIRO|869307.97   |\n",
            "|2016|null          |824372.11   |\n",
            "|2017|RIO DE JANEIRO|592847.04   |\n",
            "|2016|SAO PAULO     |475575.18   |\n",
            "|2016|RIO DE JANEIRO|348796.92   |\n",
            "|null|PERNAMBUCO    |134789.52   |\n",
            "|2020|PERNAMBUCO    |67394.76    |\n",
            "|2019|PERNAMBUCO    |67394.76    |\n",
            "+----+--------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDhW4jqlZawA"
      },
      "source": [
        "## 7.3 Análise Relacionada a Totais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCRlYyOCZwRu"
      },
      "source": [
        "O objetivo da análise desta seção é obter uma tabela de totais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZNTAgi0hg1M"
      },
      "source": [
        "### **Questão 7 (valor: 1,5)** \n",
        "\n",
        "Liste, para cada nome da região da filial, o número total de funcionários diferentes, o número total de clientes diferentes e o número total de equipes diferentes. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"REGIAO\", \"TOTALFUNCIONARIOS\", \"TOTALCLIENTES\", \"TOTALEQUIPES\". Ordene as linhas exibidas primeiro pela região em ordem descendente, depois pelo total de funcionários em ordem descendente, depois pelo total de clientes em ordem descendente, depois pelo total de equipes em ordem descendente. Liste as primeiras 25 linhas da resposta, sem truncamento das *strings*.\n",
        "\n",
        "**Resolva a questão especificando a consulta OLAP na linguagem SQL**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca8OOwWznQoS"
      },
      "source": [
        "### Resposta da Questão 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZzyESULmtIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "749625dc-2c47-4636-b163-15fc05540f56"
      },
      "source": [
        "# Resposta da Questão 7\n",
        "# Não se esqueça de finalizar a consulta mostrando seu resultado com .show()\n",
        "# Não se esqueça de exibir a resposta na saída padrão\n",
        "# Não se esqueça de gerar o arquivo no formato csv com a resposta da questão\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "-- selecionar a região da filial\n",
        "equipe.filialRegiaoNome as REGIAO, \n",
        "\n",
        "/* nas proximas 3 linhas foram utilizados a função COUNT e DISTINCT \n",
        " para contabilizar as ocorrências únicas usando os indices de cada dimensão \n",
        " \n",
        " indice funcPK para funcionarios\n",
        " indice clientePK para clientes\n",
        " indice equipePK para equipes   */\n",
        "\n",
        "count(distinct(pagamento.funcPK)) AS TOTALFUNCIONARIOS,\n",
        "count(distinct(negociacao.clientePK)) AS TOTALCLIENTES,\n",
        "count(distinct(equipe.equipePK)) AS TOTALEQUIPES\n",
        "\n",
        "-- A tabela equipe possui informação de região da filial\n",
        "FROM equipe\n",
        "\n",
        "/****** Totalização de funcionários únicos por região TOTALFUNCIONARIOS ******\n",
        "   Segundo o modelo proposto, o relacionamento entre funcionário e equipe se dá atraves da tabela de fatos pagamento */\n",
        "INNER JOIN pagamento ON pagamento.equipePK = equipe.equipePk\n",
        "\n",
        "/* Por questão de otimização não será necessário realizar o join com a tabela funcionario\n",
        "uma vez que já temos o identificador exclusivo funcPK na dimensão pagamento.\n",
        "INNER JOIN funcionario ON pagamento.funcPK = funcionario.funcPK */\n",
        "\n",
        "/******* Totalização de clientes únicos por região TOTALCLIENTES **********\n",
        "   Segundo o modelo proposto, o relacionamento entre cliente e equipe se dá atraves da tabela de fatos negociacao */\n",
        "LEFT JOIN negociacao ON negociacao.equipePK = equipe.equipePK \n",
        "\n",
        "/* Por questão de otimização não será necessário realizar o join com a tabela cliente\n",
        "uma vez que já temos o identificador exclusivo clientePK na dimensão negociacao.\n",
        "INNER JOIN cliente ON negociacao.clientePK = cliente.clientePK  */\n",
        "\n",
        "\n",
        "-- Agrupamento por região\n",
        "GROUP BY equipe.filialRegiaoNome \n",
        "ORDER BY REGIAO DESC, TOTALFUNCIONARIOS DESC, TOTALCLIENTES DESC, TOTALEQUIPES DESC\n",
        "\"\"\"\n",
        "\n",
        "# Enviando a query SQL para execução\n",
        "Questao7  = spark.sql(query)\n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "Questao7.show(25, truncate=False)\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "Questao7\\\n",
        "  .coalesce(1).limit(25) \\\n",
        "  .toPandas().to_csv(\"questao7.csv\", index=False, header=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------------+-------------+------------+\n",
            "|REGIAO      |TOTALFUNCIONARIOS|TOTALCLIENTES|TOTALEQUIPES|\n",
            "+------------+-----------------+-------------+------------+\n",
            "|SUDESTE     |134              |138          |7           |\n",
            "|NORDESTE    |20               |55           |1           |\n",
            "|CENTRO-OESTE|46               |86           |2           |\n",
            "+------------+-----------------+-------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgvlmwjQVBQm"
      },
      "source": [
        "# 8 Estendendo a Aplicação da BI Solutions\n",
        "\n",
        "A aplicação da BI Solutions está sendo estendida de forma a analisar um novo assunto de interesse: os gastos realizados na compra de equipamentos. Para tanto, é necessário criar uma nova tabela de dimensão chamada Equipamento, a qual tem como objetivo armazenar dados de equipamentos, os quais devem ser obtidos a partir de 3 fontes de dados heterogêneas.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F8-VAlRYjvf"
      },
      "source": [
        "### 8.1 Detalhamento das Fontes  \n",
        "\n",
        "Considere que o processo de integração de dados já tenha sido realizado. Como resultado, as 3 fontes de dados (Fonte1, Fonte2, Fonte3) possuem os mesmos  atributos, com os mesmos nomes. Esses atributos encontram-se listados a seguir, sendo seus nomes semânticos.\n",
        "\n",
        "- equipamentoPK\n",
        "\n",
        "- equipamentoNome\n",
        "\n",
        "- equipamentoCor\n",
        "\n",
        "- equipamentoTipo\n",
        "\n",
        "- equipamentoMoeda\n",
        "\n",
        "- equipamentoPreco \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v879EQkZs--"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Obtenção dos dados da Fonte1 e armazenamento desses dados no Dataframe chamado Fonte1\n",
        "Fonte1 = pd.read_csv('https://raw.githubusercontent.com/CristinaAguiar/QuestaoIntegra2021/main/Fonte1.csv')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzrqPkFkQOW3"
      },
      "source": [
        "# Obtenção dos dados da Fonte2 e armazenamento desses dados no Dataframe chamado Fonte2\n",
        "Fonte2 = pd.read_csv('https://raw.githubusercontent.com/CristinaAguiar/QuestaoIntegra2021/main/Fonte2.csv')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E--LvJfAQQ5x"
      },
      "source": [
        "# Obtenção dos dados da Fonte3 e armazenamento desses dados no Dataframe chamado Fonte3\n",
        "Fonte3 = pd.read_csv('https://raw.githubusercontent.com/CristinaAguiar/QuestaoIntegra2021/main/Fonte3.csv')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLR7_aLRWEGY"
      },
      "source": [
        "### 8.2 Detalhamento da tabela de dimensão Equipamento  \n",
        "\n",
        "A tabela de dimensão Equipamento da BI Solutions deve possuir os seguintes atributos:\n",
        "\n",
        "- **equipamentoPK**, correspondente aos atributos de mesmo nome nas fontes de dados.\n",
        "\n",
        "- **equipamentoNome**, correspondente aos atributos de mesmo nome nas fontes de dados.\n",
        "\n",
        "- **equipamentoDescricao**, correspondente aos atributos de mesmo nome nas fontes de dados.\n",
        "\n",
        "- **equipamentoCor**, correspondente aos atributos de mesmo nome nas fontes de dados.\n",
        "\n",
        "- **equipamentoTipo**, correspondente aos atributos de mesmo nome nas fontes de dados.\n",
        "\n",
        "- **equipamentoPreco**, correspondente aos atributos equipamentoMoeda e equipamentoPreco nas fontes de dados. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54DBU9oSWkH0"
      },
      "source": [
        "### 8.3 Regras de Negócio do Processo de Integração de Instâncias\n",
        "\n",
        "No processo de integração de instâncias, devem ser consideradas as seguintes regras de negócio:\n",
        "\n",
        "- A integração deve ser feita pelo atributo equipamentoPK. Equipamentos que possuam o mesmo valor desse atributo referem-se ao mesmo equipamento.\n",
        "\n",
        "- Todas as *strings* devem ser escritas em letras maiúsculas, sem acento e sem o uso de caracteres especiais.\n",
        "\n",
        "- Os valores das *strings* não devem ser truncados.\n",
        "\n",
        "- Os preços dos equipamentos devem ser armazenados somente em reais. Portanto, para se calcular os valores da coluna equipamentoPreco da tabela de dimensão Equipamento, deve ser feito o cálculo desse valor em reais, utilizando os atributos equipamentoMoeda e equipamentoPreco presentes nas fontes de dados originais. Considere, para isso, as seguintes conversões: (i) 1 dolar USD = 5 reais; e (ii) 1 euro EUR = 6 reais.\n",
        "\n",
        "- Os preços dos equipamentos devem ter duas casas decimais e não devem incluir a sigla \"R$\". \n",
        "\n",
        "- As cores dos equipamentos devem ser armazenadas por meio de números, da seguinte forma:\n",
        "\n",
        "  - 1: correspondente à cor PRETO nas fontes de dados\n",
        "  - 2: correspondente à cor AZUL nas fontes de dados\n",
        "  - 3: correspondente à cor BRANCO nas fontes de dados\n",
        "  - 4: correspondente à cor PRATA nas fontes de dados\n",
        "  - 5: correspondente à cor VERMELHO nas fontes de dados\n",
        "  - 6: correspondente à cor AMARELO nas fontes de dados\n",
        "\n",
        "- Para resolver inconsistências nos valores de cada atributo que aparecem nas diferentes fontes, desconsidere os valores nulos e considere que: \n",
        "\n",
        "  - (i) quando em uma coluna o valor for igual nas três fontes, esse valor deve ser armazenado na tabela de dimensão Equipamento na coluna equivalente. Por exemplo, se o nome do equipamento de PK = 1 for caneta nas três fontes de dados, então o valor a ser armazenado é CANETA.\n",
        "\n",
        "  - (ii) quando em uma coluna o valor for igual em duas fontes e diferente na terceira fonte, o  valor a ser armazenado na tabela de dimensão Equipamento na coluna equivalente é o valor que aparece nas duas fontes. Por exemplo, se o nome do equipamento de PK = 1 for caneta em duas fontes de dados e borracha na terceira fonte de dados, então o valor a ser armazenado é CANETA.\n",
        "\n",
        "  - (iii) quando em uma coluna quando o valor for diferente nas três fontes, escolhe-se por armazenar o valor da Fonte 1 na tabela de dimensão Equipamento na coluna equivalente. Caso o valor da Fonte 1 seja nulo (inexistente), escolhe-se por armazenar o valor da Fonte 2. Caso o valor da Fonte 2 também seja nulo (inexistente), escolhe-se por armazenar o valor da Fonte 3. Isso significa que Fonte1 é mais confiável do que Fonte2, a qual é mais confiável do que Fonte3. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B_xyFc3IoJ9"
      },
      "source": [
        "### **Questão 8 (valor: 2,0)** \n",
        "\n",
        "Realize a geração da tabela de dimensão Equipamento, considerando os detalhamentos dos atributos das seções 8.1 e 8.2 e as regras de negócio do processo de integração de instâncias definido na seção 8.3. A tabela de dimensão Equipamento deve possuir as colunas na ordem e com os nomes especificados a seguir: equipamentoPK, equipamentoNome, equipamentoDescricao, equipamentoCor, equipamentoTipo, equipamentoPreco. Ordene as linhas exibidas pelo atributo equipamentoPK em ordem **ascendente**. Liste **todas** as linhas da resposta, sem truncamento das *strings*.\n",
        "\n",
        "**Resolva a questão usando Pandas**. Coloque comentários detalhados explicando a sua resposta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzdJ-DJWaRaz"
      },
      "source": [
        "### Resposta da Questão 8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#Para realizar a remoção de acentuação precisamos instalar o pacote unidecode\n",
        "# que será utilizado na funcão normalizar_dataframe()\n",
        "!pip install Unidecode"
      ],
      "metadata": {
        "id": "qORnpUOsqSu7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1711
        },
        "id": "hEJEHFH1pI_P",
        "outputId": "1c0cbbfc-c962-4e86-c865-da6590a41271"
      },
      "source": [
        "import numpy as np\n",
        "import unidecode\n",
        "import re\n",
        "from pandas.api.types import is_string_dtype\n",
        "\n",
        "\n",
        "#Definição de taxas de câmbio com seguintes conversões: (i) 1 dolar USD = 5 reais; e (ii) 1 euro EUR = 6 reais. \n",
        "# será utilizado na função converter_moeda_para_real()\n",
        "TAXA_CONVERSAO = {'USD': 5, 'EUR': 6}\n",
        "\n",
        "# Vamos fazer uma copia do dataframe para não sujar os dados originais\n",
        "# Iremos trabalhar com a cópia\n",
        "A = Fonte1.copy()\n",
        "B = Fonte2.copy()\n",
        "C = Fonte3.copy()\n",
        "\n",
        "def processar_conflitos(fonte_A, fonte_B, fonte_C):\n",
        "  \"\"\"\n",
        "  Processa os conflitos das fontes com base na confiabilidade das mesmas,\n",
        "  Sendo a fonte_A a mais confiável.\n",
        "  \"\"\"\n",
        "  # Vamos percorrer cada indice de fonte_A e verifica se existem pares em fonte_B e fonte_C\n",
        "  for index in fonte_A.index:\n",
        "    row_A = fonte_A.loc[index]\n",
        "\n",
        "    exist_B = False #Flag para indentificar se indice foi encontrado em fonte_B\n",
        "    if index in fonte_B.index:\n",
        "      row_B = fonte_B.loc[index]\n",
        "      exist_B = True\n",
        "    exist_B = False #Flag para indentificar se indice foi encontrado em fonte_C\n",
        "    if index in fonte_C.index:\n",
        "      row_C = fonte_C.loc[index]\n",
        "      exist_C = True\n",
        "\n",
        "    # Caso exista valores correspondende em B e C\n",
        "    if exist_B and exist_C:    \n",
        "      #Iremos percorreer cada coluna da FonteA e realizar atualização de dados conforme a regra\n",
        "      for column in fonte_A.columns:\n",
        "        #Definição 8.3 (iii) quando valor de B e C forem iguais e A diferente, usamos o valor de B\n",
        "        if not pd.isna(row_B[column]) and row_A[column] != row_B[column] and row_B[column] == row_C[column]:\n",
        "          fonte_A.at[index, column] = row_B[column]\n",
        "  return fonte_A\n",
        "\n",
        "def converter_cores_para_numeros(dataframe):\n",
        "  \"\"\"\n",
        "  Converte cores de string para inteiro conforme o valor correspondentes abaixo:\n",
        "    1: correspondente à cor PRETO nas fontes de dados\n",
        "    2: correspondente à cor AZUL nas fontes de dados\n",
        "    3: correspondente à cor BRANCO nas fontes de dados\n",
        "    4: correspondente à cor PRATA nas fontes de dados\n",
        "    5: correspondente à cor VERMELHO nas fontes de dados\n",
        "    6: correspondente à cor AMARELO nas fontes de dados\n",
        "  \"\"\"\n",
        "  dataframe['equipamentoCor'].replace(to_replace=['PRETO', 'AZUL', 'BRANCO','PRATA','VERMELHO','AMARELO'], value=[1, 2, 3, 4, 5 ,6], inplace=True)\n",
        "  return dataframe\n",
        "\n",
        "def converter_moeda_para_real(dataframe):\n",
        "  \"\"\"\n",
        "  Realiza a conversão de 'equipamentoPreco' com taxas pré-definidas\n",
        "  Atualiza o valor 'equipamentoMoeda' para a moeda 'BRL'\n",
        "  \"\"\"\n",
        "  def converte_valor(valor,moeda):\n",
        "    return valor*TAXA_CONVERSAO[moeda]\n",
        "\n",
        "  # Para cada moeda encontrado no dataframe iremos aplicar a taxa de conversão\n",
        "  for moeda in TAXA_CONVERSAO:\n",
        "    dataframe.loc[dataframe['equipamentoMoeda'] == moeda,'equipamentoPreco'] = dataframe[dataframe['equipamentoMoeda'] == moeda]['equipamentoPreco'].apply(converte_valor,moeda=moeda)\n",
        "    dataframe.loc[dataframe['equipamentoMoeda'] == moeda,'equipamentoMoeda'] = dataframe[dataframe['equipamentoMoeda'] == moeda]['equipamentoMoeda'] = 'BRL'\n",
        "\n",
        "  return dataframe\n",
        "\n",
        "\n",
        "def normalizar_dataframe(dataframe):\n",
        "  \"\"\"\n",
        "   Função para normalizar as strings: todas as strings devem ser escritas em letras maiúsculas, sem acento e sem o uso de caracteres especiais.\n",
        "  \"\"\"\n",
        "  def normalizar_texto(valor):  \n",
        "    #Primeiro vamos remover qualquer acento dos caracteres, ex.: Á vira A\n",
        "    remove_acentos = unidecode.unidecode(valor)\n",
        "    #Segundo vamos remover todos o caracteres especiais emanter somente caractere alphanuméricos e espaços\n",
        "    remove_especiais = re.sub(r'\\W\\s+', '', remove_acentos)\n",
        "    #Por úlitmo vamos converter a string para letras maiúsculas\n",
        "    return remove_especiais.upper()\n",
        "\n",
        "  #Iremos percorrer cada coluna do dataframe para aplicar a normalização\n",
        "  for nome_coluna in dataframe.columns:\n",
        "    #A normalização de string só pode ocorrer em colunas do tipo String, a função is_string_dtype do pandas faz essa checagem :)\n",
        "    if is_string_dtype(dataframe[nome_coluna]):\n",
        "      dataframe[nome_coluna] = dataframe[[nome_coluna]].applymap(normalizar_texto)\n",
        "  return dataframe\n",
        "\n",
        "\n",
        "\"\"\"def validar_dados(dataframe):\n",
        "  for nome_coluna in df1.columns.values[1:]: \"\"\"\n",
        "    \n",
        "\n",
        "def preprocessamento_dataframe(df):\n",
        "  \"\"\"\n",
        "  Clona o DataFrame, e altera o indice para funcMatricula\n",
        "  \"\"\"\n",
        "  ndf = df.copy(deep=True)\n",
        "  return ndf.set_index('equipamentoPK')\n",
        "\n",
        "\n",
        "def merge_null_todas_colunas(df1,df2):\n",
        "\n",
        "  # Iremos fazer um full merge do dataframe 1 com o 2\n",
        "  # Especificando how=outer para unir todas as linhas do dataframe esquerdo e todas as linhas do dataframe direito.\n",
        "  novo = pd.merge(df1,df2,on='equipamentoPK', how='outer')\n",
        "\n",
        "  # Vamos percorrer cada coluna do dataframe, exceto a primeira que é PK\n",
        "  for nome_coluna in df1.columns.values[1:]:  \n",
        "\n",
        "    #Vamos obter o indice de localização da coluna (ordem) para recriarmos no menos lugar\n",
        "    idx_coluna = df1.columns.get_loc(nome_coluna)\n",
        "\n",
        "    #A operação de merge renomeou as colunas para o padrão coluna_x e coluna_y, vamos recriar a original no mesmo local inicial com valor NaN\n",
        "    novo.insert(idx_coluna,nome_coluna,np.nan)\n",
        "\n",
        "    #Vamos preenchar a coluna recriada com o o valor da coluna_x (primeiro dataframe), caso esse valor seja NULO iremos usar o valor da coluna_y(segundo dataframe)\n",
        "    # Essa regra atende ao quesito Caso o valor da Fonte 1 seja nulo (inexistente), escolhe-se por armazenar o valor da Fonte 2.\n",
        "    novo[nome_coluna] = novo.apply(lambda row: row[f\"{nome_coluna}_y\"] if pd.isna(row[f\"{nome_coluna}_x\"]) else row[f\"{nome_coluna}_x\"], axis=1)\n",
        "    novo.drop([f\"{nome_coluna}_y\",f\"{nome_coluna}_x\"], axis='columns', inplace=True)\n",
        "  return novo\n",
        "\n",
        "\n",
        "#Primeiro passo é obter um dataframe com merge de FonteA,FonteB e FonteC\n",
        "#Vamos inicar o merge com FonteA e FonteA\n",
        "df_processado = merge_null_todas_colunas(A,B)\n",
        "\n",
        "#Em sequencia vamos pegar o resultado e fazer merge com FonteC\n",
        "df_processado = merge_null_todas_colunas(df_processado,C)\n",
        "\n",
        "#Agora iremos indexar o dataframe com a PK equipamentoPK\n",
        "df_processado_indexado = preprocessamento_dataframe(df_processado)\n",
        "\n",
        "#Agora iremos indexar a FonteB com a PK equipamentoPK\n",
        "FonteB_indexada = preprocessamento_dataframe(B)\n",
        "#Agora iremos indexar a FonteC com a PK equipamentoPK\n",
        "FonteC_indexada = preprocessamento_dataframe(C)\n",
        "\n",
        "# Comandos para resolver indices do conflito de df_processado_indexado(primário), FonteB_indexada e FonteC_indexada (secundários)\n",
        "df_processado = processar_conflitos(df_processado_indexado, FonteB_indexada, FonteC_indexada)\n",
        "\n",
        "# Aplicar a funçõa para normalizar as STRINGS\n",
        "# Todas as strings devem ser escritas em letras maiúsculas, sem acento e sem o uso de caracteres especiais.\n",
        "df_processado = normalizar_dataframe(df_processado)\n",
        "\n",
        "# Aplicar função para realizar a conversão de moedas estrangeiras para Real\n",
        "df_processado = converter_moeda_para_real(df_processado)\n",
        "\n",
        "# Aplicar função para realizar a conversão de cores\n",
        "Questao8 = converter_cores_para_numeros(df_processado)\n",
        "\n",
        "#Aplicar ordenação de indice (equipamentoPK)\n",
        "Questao8 = Questao8.sort_index()\n",
        "\n",
        "# Exibe a resposta da questão na saída padrão\n",
        "display(Questao8)\n",
        "\n",
        "# Gera o arquivo no formato csv com a resposta da questão\n",
        "Questao8.to_csv(\"questao8.csv\", index=False, header=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>equipamentoNome</th>\n",
              "      <th>equipamentoDescricao</th>\n",
              "      <th>equipamentoCor</th>\n",
              "      <th>equipamentoTipo</th>\n",
              "      <th>equipamentoMoeda</th>\n",
              "      <th>equipamentoPreco</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>equipamentoPK</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MONITOR</td>\n",
              "      <td>MONITOR LCD LG 15 POLEGADAS</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>234.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MONITOR</td>\n",
              "      <td>MONITOR LCD ITAUTEC 19 POLEGADAS</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>180.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MONITOR</td>\n",
              "      <td>MONITOR LCD AOC 17 POLEGADAS</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>167.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>LENOVO THINKCENTRE MT-M WINTEL CORE 2 DUO 2.33...</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>2399.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>LENOVO THINKCENTRE MT-M WINTEL CORE 2 DUO 2.33...</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>2399.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>ITAUTEC INFOWAY SM 3322 WAMD PHENOM X2 8GB 320...</td>\n",
              "      <td>4</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1877.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>POSITIVO PLUS R70 WMOBO ITAUTEC SM3322 AMD PHE...</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>3500.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>ITAUTEC INFOWAY ST 1430 WMB ITAUTEC SM3322 AMD...</td>\n",
              "      <td>4</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1474.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>HP COMPAQ DC5850 WAMD PHENOM X4 4GB RAM 250GB HD</td>\n",
              "      <td>4</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1500.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>HP COMPAQ DC5850 WAMD PHENOM X4 4GB RAM 250GB HD</td>\n",
              "      <td>4</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1583.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>HP COMPAQ DC5850 WAMD PHENOM X4 8GB RAM 250GB HD</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1250.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>HP COMPAQ DC5850 WAMD PHENOM X4 16GB RAM 250GB HD</td>\n",
              "      <td>4</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>2300.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>HP COMPAQ DC5850 WAMD PHENOM X4 16GB RAM 250GB HD</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>2300.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>PAUTA CONNECT BB8701A WMOBO ITAUTEC SM3322 AMD...</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>2554.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CADEIRA DE ESCRITORIO</td>\n",
              "      <td>CADEIRA DE ESCRITORIO COM RODAS REVESTIDA EM T...</td>\n",
              "      <td>2</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>133.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>CADEIRA DE ESCRITORIO</td>\n",
              "      <td>CADEIRA DE ESCRITORIO COM RODAS REVESTIDA EM T...</td>\n",
              "      <td>2</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>577.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CADEIRA DE ESCRITORIO</td>\n",
              "      <td>CADEIRA DE ESCRITORIO COM RODAS REVESTIDA EM T...</td>\n",
              "      <td>1</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>577.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>CADEIRA DE ESCRITORIO</td>\n",
              "      <td>CADEIRA DE ESCRITORIO COM RODAS REVESTIDA EM T...</td>\n",
              "      <td>2</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>577.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>CADEIRA DE ESCRITORIO</td>\n",
              "      <td>CADEIRA DE ESCRITORIO COM RODAS REVESTIDA EM T...</td>\n",
              "      <td>2</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>501.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>CADEIRA DE ESCRITORIO</td>\n",
              "      <td>CADEIRA DE ESCRITORIO REVESTIDA EM TECIDO NA C...</td>\n",
              "      <td>2</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>577.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>CADEIRA DE ESCRITORIO</td>\n",
              "      <td>CADEIRA UNIVERSITARIA REVESTIDA EM TECIDO NA C...</td>\n",
              "      <td>2</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>214.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>CADEIRA DE ESCRITORIO</td>\n",
              "      <td>CADEIRA UNIVERSITARIA REVESTIDA EM TECIDO NA C...</td>\n",
              "      <td>2</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>214.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>CADEIRA DE ESCRITORIO</td>\n",
              "      <td>CADEIRA UNIVERSITARIA REVESTIDA EM TECIDO NA C...</td>\n",
              "      <td>3</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>214.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ESTABILIZADOR</td>\n",
              "      <td>ESTABILIZADOR RAGTECH 24801500 VA</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>909.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>ESTABILIZADOR</td>\n",
              "      <td>ESTABILIZADOR RAGTECH 34801500 VA</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>859.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ESTABILIZADOR</td>\n",
              "      <td>ESTABILIZADOR RAGTECH 34801500 VA</td>\n",
              "      <td>4</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>919.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>CONDICIONADOR</td>\n",
              "      <td>CONDICIONADOR DE AR GREE GWCO9MA-DINNA3C/I 900...</td>\n",
              "      <td>3</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1599.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>QUADRO-BRANCO</td>\n",
              "      <td>QUADRO-BRANCO REVESTIDO EM FORMICA COM MOLDURA...</td>\n",
              "      <td>3</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>134.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>SUPORTE GABINETE</td>\n",
              "      <td>SUPORTE PARA GABINETE E ESTABILIZADOR REVESTID...</td>\n",
              "      <td>3</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>139.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>HP PAVILION 20 ALL-IN-ONE PC INTEL CORE I3</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1750.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>MONITOR</td>\n",
              "      <td>MONITOR HP L190HB 19 POLEGADAS</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>650.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>MONITOR</td>\n",
              "      <td>MONITOR HP L190HB 19 POLEGADAS</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>650.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>MONITOR</td>\n",
              "      <td>MONITOR HP L190HB 19 POLEGADAS</td>\n",
              "      <td>3</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>650.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>HP PAVILION 20 ALL-IN-ONE PC INTEL CORE I3</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1750.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>HP PAVILION 20 ALL-IN-ONE PC INTEL CORE I3</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1839.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>MONITOR</td>\n",
              "      <td>MONITOR GAMER FULL HD LED SAMSUNG 27 POLEGADAS</td>\n",
              "      <td>3</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>899.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>COMPUTADOR</td>\n",
              "      <td>DELL INSPIRON INS-3470-M40 8A GERACAO INTEL CO...</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>2500.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>ROTEADOR</td>\n",
              "      <td>ROTEADOR RE057 MULTILASER</td>\n",
              "      <td>3</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>90.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>ROTEADOR</td>\n",
              "      <td>ROTEADOR RE057 MULTILASER</td>\n",
              "      <td>1</td>\n",
              "      <td>EQUIP INFORMATICA</td>\n",
              "      <td>BRL</td>\n",
              "      <td>110.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>CAFETEIRA</td>\n",
              "      <td>CAFETEIRA BRITANIA 12 XICARAS</td>\n",
              "      <td>4</td>\n",
              "      <td>ELETRODOMESTICO</td>\n",
              "      <td>BRL</td>\n",
              "      <td>144.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>MICRO-ONDAS</td>\n",
              "      <td>FORNO DE MICRO-ONDAS ELECTROLUX MTO30 20L BRANCO</td>\n",
              "      <td>3</td>\n",
              "      <td>ELETRODOMESTICO</td>\n",
              "      <td>BRL</td>\n",
              "      <td>494.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>GELADEIRA</td>\n",
              "      <td>REFRIGERADOR ELECTROLUX DUPLEX DC35A 260L BRANCO</td>\n",
              "      <td>3</td>\n",
              "      <td>ELETRODOMESTICO</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1949.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>MESA</td>\n",
              "      <td>MESA RETANGULAR 60 CM</td>\n",
              "      <td>3</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>549.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>MESA</td>\n",
              "      <td>MESA REDONDA REVESTIDA EM FORMICA</td>\n",
              "      <td>3</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>549.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>CADEIRA</td>\n",
              "      <td>CADEIRA PREMIUM</td>\n",
              "      <td>3</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>665.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>CADEIRA</td>\n",
              "      <td>CADEIRA PREMIUM</td>\n",
              "      <td>1</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>665.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>CADEIRA</td>\n",
              "      <td>CADEIRA PLASTICA</td>\n",
              "      <td>3</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>FURADEIRA</td>\n",
              "      <td>PARAFUSADEIRA E FURADEIRA BOSCH GSR 7-14 E 400...</td>\n",
              "      <td>2</td>\n",
              "      <td>FERRAMENTAS ELETRICAS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>249.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>SERRA</td>\n",
              "      <td>SERRA CIRCULAR WAP ESC 1400 FERRAMENTA ELETRIC...</td>\n",
              "      <td>6</td>\n",
              "      <td>FERRAMENTAS ELETRICAS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1320.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>SERRA</td>\n",
              "      <td>SERRA TICO-TICO BOSCH GST 650 450W 127V</td>\n",
              "      <td>2</td>\n",
              "      <td>FERRAMENTAS ELETRICAS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>313.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>POLTRONA</td>\n",
              "      <td>POLTRONA VILLARE SOGNO RECLINAVEL REVESTIDA EM...</td>\n",
              "      <td>5</td>\n",
              "      <td>MOVEIS</td>\n",
              "      <td>BRL</td>\n",
              "      <td>845.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>SMARTPHONE</td>\n",
              "      <td>XIAOMI MI A2 LITE 3GB RAM 32GB ARMAZENAMENTO A...</td>\n",
              "      <td>4</td>\n",
              "      <td>SMARTPHONES</td>\n",
              "      <td>BRL</td>\n",
              "      <td>1177.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     equipamentoNome  ... equipamentoPreco\n",
              "equipamentoPK                         ...                 \n",
              "1                            MONITOR  ...           234.00\n",
              "2                            MONITOR  ...           180.20\n",
              "3                            MONITOR  ...           167.41\n",
              "4                         COMPUTADOR  ...          2399.41\n",
              "5                         COMPUTADOR  ...          2399.41\n",
              "6                         COMPUTADOR  ...          1877.84\n",
              "7                         COMPUTADOR  ...          3500.47\n",
              "8                         COMPUTADOR  ...          1474.87\n",
              "9                         COMPUTADOR  ...          1500.00\n",
              "10                        COMPUTADOR  ...          1583.74\n",
              "11                        COMPUTADOR  ...          1250.00\n",
              "12                        COMPUTADOR  ...          2300.74\n",
              "13                        COMPUTADOR  ...          2300.74\n",
              "14                        COMPUTADOR  ...          2554.85\n",
              "15             CADEIRA DE ESCRITORIO  ...           133.00\n",
              "16             CADEIRA DE ESCRITORIO  ...           577.16\n",
              "17             CADEIRA DE ESCRITORIO  ...           577.17\n",
              "18             CADEIRA DE ESCRITORIO  ...           577.18\n",
              "19             CADEIRA DE ESCRITORIO  ...           501.50\n",
              "20             CADEIRA DE ESCRITORIO  ...           577.20\n",
              "21             CADEIRA DE ESCRITORIO  ...           214.00\n",
              "22             CADEIRA DE ESCRITORIO  ...           214.01\n",
              "23             CADEIRA DE ESCRITORIO  ...           214.02\n",
              "24                     ESTABILIZADOR  ...           909.35\n",
              "25                     ESTABILIZADOR  ...           859.41\n",
              "26                     ESTABILIZADOR  ...           919.27\n",
              "27                     CONDICIONADOR  ...          1599.00\n",
              "28                     QUADRO-BRANCO  ...           134.99\n",
              "29                  SUPORTE GABINETE  ...           139.90\n",
              "30                        COMPUTADOR  ...          1750.00\n",
              "31                           MONITOR  ...           650.00\n",
              "32                           MONITOR  ...           650.00\n",
              "33                           MONITOR  ...           650.00\n",
              "34                        COMPUTADOR  ...          1750.00\n",
              "35                        COMPUTADOR  ...          1839.47\n",
              "36                           MONITOR  ...           899.00\n",
              "37                        COMPUTADOR  ...          2500.00\n",
              "38                          ROTEADOR  ...            90.80\n",
              "39                          ROTEADOR  ...           110.00\n",
              "40                         CAFETEIRA  ...           144.36\n",
              "41                       MICRO-ONDAS  ...           494.10\n",
              "42                         GELADEIRA  ...          1949.00\n",
              "43                              MESA  ...           549.98\n",
              "44                              MESA  ...           549.98\n",
              "45                           CADEIRA  ...           665.00\n",
              "46                           CADEIRA  ...           665.00\n",
              "47                           CADEIRA  ...            30.00\n",
              "48                         FURADEIRA  ...           249.99\n",
              "49                             SERRA  ...          1320.60\n",
              "50                             SERRA  ...           313.20\n",
              "51                          POLTRONA  ...           845.50\n",
              "52                        SMARTPHONE  ...          1177.00\n",
              "\n",
              "[52 rows x 6 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}